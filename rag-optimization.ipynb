{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiating ollama Client with llama3.2:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ollama pull llama3.2:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "\n",
    "client = Client(\n",
    "  host='http://localhost:11434',\n",
    "  headers={'x-some-header': 'some-value'}\n",
    ")\n",
    "response = client.chat(model='llama3.2:1b', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring the DSPy environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "lm = dspy.LM('ollama_chat/llama3.2:1b', api_base='http://localhost:11434', api_key='')\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The sky appears blue to us because of a phenomenon called Rayleigh scattering, named after the British physicist Lord Rayleigh. He discovered that when sunlight enters Earth's atmosphere, it encounters tiny molecules of gases such as nitrogen and oxygen.\\n\\nThese molecules scatter the light in all directions, but they scatter shorter (blue) wavelengths more than longer (red) wavelengths. This is because the smaller molecules are more effective at scattering the blue light.\\n\\nAs a result, the blue light is distributed throughout the atmosphere, giving the sky its blue color. The other colors of the visible spectrum, such as red and orange, are scattered less and remain closer to the direction of the sun, which is why they appear more intense in the sky during the day.\\n\\nIt's worth noting that the sky can take on a range of colors depending on the time of day, atmospheric conditions, and other factors. For example, during sunrise and sunset, the sky can take on hues of red, orange, and pink due to the scattering of light by atmospheric particles. And at night, the sky can appear dark or even black if there are no stars or other light sources present.\\n\\nOverall, the blue color of the sky is a result of the way that sunlight interacts with the tiny molecules in our atmosphere, and it's a beautiful and fascinating phenomenon that we get to enjoy every day!\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm(\"Why is the sky blue?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and prepare q&a data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'why igp is used in mpls?',\n",
       " 'response': \"An IGP exchanges routing prefixes between gateways/routers.  \\nWithout a routing protocol, you'd have to configure each route on every router and you'd have no dynamic updates when routes change because of link failures. \\nFuthermore, within an MPLS network, an IGP is vital for advertising the internal topology and ensuring connectivity for MP-BGP inside the network.\",\n",
       " 'gold_doc_ids': [2822, 2823]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ujson\n",
    "from dspy.utils import download\n",
    "\n",
    "# Download question--answer pairs from the RAG-QA Arena \"Tech\" dataset.\n",
    "download(\"https://huggingface.co/dspy/cache/resolve/main/ragqa_arena_tech_examples.jsonl\")\n",
    "\n",
    "with open(\"ragqa_arena_tech_examples.jsonl\") as f:\n",
    "    data = [ujson.loads(line) for line in f]\n",
    "\n",
    "# Inspect one datapoint.\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example({'question': 'why are my text messages coming up as maybe?', 'response': 'This is part of the Proactivity features new with iOS 9: It looks at info in emails to see if anyone with this number sent you an email and if it finds the phone number associated with a contact from your email, it will show you \"Maybe\". \\n\\nHowever, it has been suggested there is a bug in iOS 11.2 that can result in \"Maybe\" being displayed even when \"Find Contacts in Other Apps\" is disabled.', 'gold_doc_ids': [3956, 3957, 8034]}) (input_keys={'question'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [dspy.Example(**d).with_inputs('question') for d in data]\n",
    "\n",
    "# Let's pick an `example` here from the data.\n",
    "example = data[2]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 30, 50)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Shuffle the data for training, dev, and test sets.\n",
    "random.Random(0).shuffle(data)\n",
    "trainset, devset, testset = data[:20], data[20:50], data[50:100]\n",
    "\n",
    "len(trainset), len(devset), len(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up vector db and collection for retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "persist_directory=\"vector_db\"\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=persist_directory)\n",
    "\n",
    "# Default: Sentence Transformers all-MiniLM-L6-v2\n",
    "default_ef = embedding_functions.DefaultEmbeddingFunction()\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=\"ragqa_arena_tech_corpus\",\n",
    "    embedding_function=default_ef,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare corpus for vector db and add to collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download(\"https://huggingface.co/dspy/cache/resolve/main/ragqa_arena_tech_corpus.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ujson\n",
    "\n",
    "with open(\"ragqa_arena_tech_corpus.jsonl\") as f:\n",
    "    corpus = [ujson.loads(line) for line in f]\n",
    "    print(f\"Loaded {len(corpus)} documents. Will encode them below.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate corpus to max_characters and add to collection\n",
    "\n",
    "max_characters = 6000  # for truncating >99th percentile of documents\n",
    "corpus = [\n",
    "    {\n",
    "        'text': d['text'][:max_characters],\n",
    "        'doc_id': d['doc_id'],\n",
    "        'author': d['author'],\n",
    "    } \n",
    "    for d in corpus\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=[d['text'] for d in corpus],\n",
    "    ids=[str(d['doc_id']) for d in corpus]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.retrieve.chromadb_rm import ChromadbRM\n",
    "\n",
    "topk_docs_to_retrieve = 5\n",
    "collection_name = \"ragqa_arena_tech_corpus\"\n",
    "\n",
    "retriever = ChromadbRM(\n",
    "    collection_name=collection_name,\n",
    "    k=topk_docs_to_retrieve,\n",
    "    embedding_function=default_ef,\n",
    "    client=chroma_client,\n",
    "    persist_directory=persist_directory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '78968',\n",
       "  'score': 0.7096676826477051,\n",
       "  'long_text': 'Youre not sending them all the past messages, its just loading up your past conversation, and your text is the next message in the conversation. You could get it so it doesnt save message histories and then you wouldnt see past messages, or you can have it so it does save messages histories and you do see past messages. But its just what you see thats different.',\n",
       "  'metadatas': None},\n",
       " {'id': '54242',\n",
       "  'score': 0.7977485656738281,\n",
       "  'long_text': 'The sent as text message means your text message was sent using SMS, not iMessage. Because the message wasnt sent through iMessage, neither you or the person you are texting to have access to read receipts, which allow you to see whether or not the person you sent the text message to read your message. This often happens if youre in an area with bad signal, with no access to wifi, 3G, or LTE coverage and the message can only be sent via SMS.',\n",
       "  'metadatas': None},\n",
       " {'id': '140407',\n",
       "  'score': 0.8438153266906738,\n",
       "  'long_text': 'Some troubleshooting suggestions: Does the SMS only show up in GO, or does it also show up in the stock Messaging app? If it only shows up in GO, we know its an issue with that app. If not, an actual sms is being received by your phone. If its a GO problem, try clearing the GO app cache completely. If the issue still persists, explore if it might be contact related as someone else suggested. If you sync your contacts with Google, temporarily un-sync them so they go away and reboot. Do you still get an sms? If youre actually getting an SMS (feels unlikely) you might want to contact your carrier just in case, they will probably be able to submit an error report so that someone can look into it. Please supply more info on how your problem develops and Ill try to expand my answer.',\n",
       "  'metadatas': None},\n",
       " {'id': '134346',\n",
       "  'score': 0.8584445118904114,\n",
       "  'long_text': 'If you are using the stock messaging app, the settings might be the cause of the trouble. Go to Messaging app -> Settings -> Untick Delete old messages. (If it was ticked Im sure that was the reason for auto deleting of the sms)',\n",
       "  'metadatas': None},\n",
       " {'id': '49358',\n",
       "  'score': 0.885087251663208,\n",
       "  'long_text': 'Several things can cause this. I would need more information to give you an accurate answer. If you are using iMessage it could be that a number or email in the group is somehow associated with your contact information. Go to Settings>Msessages and make sure that only one phone number and AppleID is linked to your account. Check the group and make sure you only see your email or your phone number in the list, not both. If its SMS contact your carrier as that is controlled by the carrier programing.',\n",
       "  'metadatas': None}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test retriever\n",
    "retriever(example['question'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG(dspy.Module):\n",
    "    def __init__(self, retriever):\n",
    "        self.respond = dspy.ChainOfThought('context, question -> response')\n",
    "        self.retriever = retriever\n",
    "\n",
    "    def forward(self, question):\n",
    "        docs = self.retriever(question)\n",
    "        context = \"\\n\\n\".join([f\"[{i+1}] {doc.long_text}\" for i, doc in enumerate(docs)])\n",
    "        return self.respond(context=context, question=question)\n",
    "\n",
    "rag = RAG(retriever)\n",
    "rag(question=\"what are high memory and low memory on linux?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.inspect_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.evaluate import SemanticF1\n",
    "\n",
    "# Instantiate the metric.\n",
    "metric = SemanticF1(decompositional=True)\n",
    "\n",
    "# Produce a prediction from our `rag` module, using the `example` above as input.\n",
    "pred = rag(**example.inputs())\n",
    "\n",
    "# Compute the metric score for the prediction.\n",
    "score = metric(example, pred)\n",
    "\n",
    "print(f\"Question: \\t {example.question}\\n\")\n",
    "print(f\"Gold Response: \\t {example.response}\\n\")\n",
    "print(f\"Predicted Response: \\t {pred.response}\\n\")\n",
    "print(f\"Semantic F1 Score: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an evaluator that we can re-use.\n",
    "evaluate = dspy.Evaluate(devset=devset, metric=metric, display_progress=True, display_table=True)\n",
    "\n",
    "# Evaluate the Chain-of-Thought program.\n",
    "evaluate(rag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = sum([x['cost'] for x in lm.history if x['cost'] is not None])  # in USD, as calculated by LiteLLM for certain providers\n",
    "cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = dspy.MIPROv2(metric=metric, auto=\"light\", num_threads=2)  # use fewer threads if your rate limit is small\n",
    "\n",
    "optimized_rag = tp.compile(\n",
    "    RAG(retriever), \n",
    "    trainset=trainset,\n",
    "    max_bootstrapped_demos=2, \n",
    "    max_labeled_demos=2,\n",
    "    requires_permission_to_run=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = rag(question=\"cmd+tab does not work on hidden or minimized windows\")\n",
    "print(baseline.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = optimized_rag(question=\"cmd+tab does not work on hidden or minimized windows\")\n",
    "print(pred.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.inspect_history(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(optimized_rag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the optimized model\n",
    "optimized_rag.save(\"rag-optimized.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the optimized model\n",
    "loaded_rag = RAG(retriever)\n",
    "loaded_rag.load(\"rag-optimized.json\")\n",
    "\n",
    "loaded_rag(question=\"cmd+tab does not work on hidden or minimized windows\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
